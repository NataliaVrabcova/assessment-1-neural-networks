{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4c/6JD79OQvCSUM/y5J+q"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qJT2SJFzek46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62bdcc07-adf0-47e1-ce01-533e0a7ba7f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'assessment-1-neural-networks'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 9 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (9/9), 2.01 MiB | 11.41 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NataliaVrabcova/assessment-1-neural-networks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Adjust the path to match your repository structure\n",
        "data = pd.read_csv('/content/assessment-1-neural-networks/healthcare_noshows_appointments.csv')\n",
        "\n",
        "# Verify the dataset is loaded\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOhms_5agG9I",
        "outputId": "53f8ab6f-103c-4040-9e73-4ee2a8691cd5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      PatientId  AppointmentID Gender ScheduledDay AppointmentDay  Age  \\\n",
            "0  2.987250e+13        5642903      F   2016-04-29     2016-04-29   62   \n",
            "1  5.589978e+14        5642503      M   2016-04-29     2016-04-29   56   \n",
            "2  4.262962e+12        5642549      F   2016-04-29     2016-04-29   62   \n",
            "3  8.679512e+11        5642828      F   2016-04-29     2016-04-29    8   \n",
            "4  8.841186e+12        5642494      F   2016-04-29     2016-04-29   56   \n",
            "\n",
            "       Neighbourhood  Scholarship  Hipertension  Diabetes  Alcoholism  \\\n",
            "0    JARDIM DA PENHA        False          True     False       False   \n",
            "1    JARDIM DA PENHA        False         False     False       False   \n",
            "2      MATA DA PRAIA        False         False     False       False   \n",
            "3  PONTAL DE CAMBURI        False         False     False       False   \n",
            "4    JARDIM DA PENHA        False          True      True       False   \n",
            "\n",
            "   Handcap  SMS_received  Showed_up  Date.diff  \n",
            "0    False         False       True          0  \n",
            "1    False         False       True          0  \n",
            "2    False         False       True          0  \n",
            "3    False         False       True          0  \n",
            "4    False         False       True          0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Input\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "zI3gtgDdggVZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing the Data"
      ],
      "metadata": {
        "id": "CXsF4oD6gz_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting features and target variable\n",
        "X = data.drop(['Showed_up', 'PatientId', 'AppointmentID'], axis=1)\n",
        "y = data['Showed_up']\n",
        "\n",
        "# Encoding categorical variables\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "fAjwQuJIgx0I"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the architecture of the neural network:"
      ],
      "metadata": {
        "id": "hc6LdNHkg1YR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the neural network model\n",
        "model = Sequential([\n",
        "    Input(shape=(X_train.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "BoWrhYMYg3N0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Adam **optimizer was chosen due to its adaptability and efficiency in handling sparse gradients. The default learning rate of 0.001 was used, as it generally works well for a wide range of tasks and often provides a good starting point for optimization. This ensures stable and efficient convergence without the need for extensive fine-tuning."
      ],
      "metadata": {
        "id": "9VqV4uAq6cGf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model with your preprocessed data:"
      ],
      "metadata": {
        "id": "UfSZYeyIhMeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=25, batch_size=32, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38eDevsChOZD",
        "outputId": "52e9cdeb-1cdd-4ce2-b906-e91612c10326"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m2675/2675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.8028 - loss: 0.4330 - val_accuracy: 0.8000 - val_loss: 0.4476\n",
            "Epoch 2/25\n",
            "\u001b[1m2675/2675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.8012 - loss: 0.4341 - val_accuracy: 0.8004 - val_loss: 0.4489\n",
            "Epoch 3/25\n",
            "\u001b[1m2675/2675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8015 - loss: 0.4326 - val_accuracy: 0.7999 - val_loss: 0.4517\n",
            "Epoch 4/25\n",
            "\u001b[1m2675/2675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8008 - loss: 0.4356 - val_accuracy: 0.7988 - val_loss: 0.4533\n",
            "Epoch 5/25\n",
            "\u001b[1m2675/2675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8012 - loss: 0.4342 - val_accuracy: 0.7992 - val_loss: 0.4503\n",
            "Epoch 6/25\n",
            "\u001b[1m2675/2675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8010 - loss: 0.4329 - val_accuracy: 0.7991 - val_loss: 0.4490\n",
            "Epoch 7/25\n",
            "\u001b[1m2675/2675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8026 - loss: 0.4322 - val_accuracy: 0.7987 - val_loss: 0.4483\n",
            "Epoch 8/25\n",
            "\u001b[1m2675/2675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8028 - loss: 0.4337 - val_accuracy: 0.7992 - val_loss: 0.4507\n",
            "Epoch 9/25\n",
            "\u001b[1m2675/2675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8026 - loss: 0.4310 - val_accuracy: 0.7991 - val_loss: 0.4502\n",
            "Epoch 10/25\n",
            "\u001b[1m2675/2675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8031 - loss: 0.4321 - val_accuracy: 0.7988 - val_loss: 0.4488\n",
            "Epoch 11/25\n",
            "\u001b[1m2675/2675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8036 - loss: 0.4315 - val_accuracy: 0.7997 - val_loss: 0.4523\n",
            "Epoch 12/25\n",
            "\u001b[1m2675/2675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.8013 - loss: 0.4335 - val_accuracy: 0.8000 - val_loss: 0.4516\n",
            "Epoch 13/25\n",
            "\u001b[1m2675/2675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.7999 - loss: 0.4364 - val_accuracy: 0.8000 - val_loss: 0.4509\n",
            "Epoch 14/25\n",
            "\u001b[1m2675/2675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8031 - loss: 0.4315 - val_accuracy: 0.7993 - val_loss: 0.4489\n",
            "Epoch 15/25\n",
            "\u001b[1m2675/2675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8028 - loss: 0.4332 - val_accuracy: 0.7993 - val_loss: 0.4492\n",
            "Epoch 16/25\n",
            "\u001b[1m2675/2675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8010 - loss: 0.4351 - val_accuracy: 0.7997 - val_loss: 0.4496\n",
            "Epoch 17/25\n",
            "\u001b[1m2675/2675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8029 - loss: 0.4315 - val_accuracy: 0.7989 - val_loss: 0.4524\n",
            "Epoch 18/25\n",
            "\u001b[1m2675/2675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8041 - loss: 0.4297 - val_accuracy: 0.7998 - val_loss: 0.4494\n",
            "Epoch 19/25\n",
            "\u001b[1m2675/2675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8025 - loss: 0.4318 - val_accuracy: 0.7995 - val_loss: 0.4483\n",
            "Epoch 20/25\n",
            "\u001b[1m2675/2675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.8040 - loss: 0.4302 - val_accuracy: 0.7996 - val_loss: 0.4502\n",
            "Epoch 21/25\n",
            "\u001b[1m2675/2675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8017 - loss: 0.4333 - val_accuracy: 0.8002 - val_loss: 0.4514\n",
            "Epoch 22/25\n",
            "\u001b[1m2675/2675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8008 - loss: 0.4328 - val_accuracy: 0.8002 - val_loss: 0.4496\n",
            "Epoch 23/25\n",
            "\u001b[1m2675/2675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8006 - loss: 0.4350 - val_accuracy: 0.7993 - val_loss: 0.4503\n",
            "Epoch 24/25\n",
            "\u001b[1m2675/2675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8025 - loss: 0.4329 - val_accuracy: 0.7994 - val_loss: 0.4494\n",
            "Epoch 25/25\n",
            "\u001b[1m2675/2675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.8011 - loss: 0.4325 - val_accuracy: 0.7997 - val_loss: 0.4486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model was trained for 25 epochs. This number was selected to allow the model sufficient iterations to learn patterns in the data while avoiding overfitting. Early stopping techniques could be employed in future experiments to determine the optimal number of epochs dynamically based on validation performance."
      ],
      "metadata": {
        "id": "w-4Lv5tr6lNl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model’s performance:"
      ],
      "metadata": {
        "id": "6Re5Ik1ThPE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NBmsJRDhTtN",
        "outputId": "b9b1eb92-5ed3-4833-e261-0de1a2458d5f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Accuracy: 0.7997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model on the test set"
      ],
      "metadata": {
        "id": "QNvkpyt9mH_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "7yTVyktAmBvL",
        "outputId": "70bddd38-879b-4188-922e-2d9acbb3399f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7976 - loss: 0.4510\n",
            "Test Loss: 0.44962742924690247\n",
            "Test Accuracy: 0.7992335557937622\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Loss:\n",
        "  This value indicates the average error (or loss) of the model when it made predictions on the test data. A lower loss generally means that the model made fewer mistakes.\n",
        "\n",
        "Test Accuracy:\n",
        "  This metric shows the proportion of correct predictions (true positives + true negatives) out of the total predictions on the test set. A value closer to 1 indicates better performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "QfR3U96zmEG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Given parameters\n",
        "X = np.random.rand(100, 14)  # Example data (100 samples, 14 features)\n",
        "W1 = np.random.rand(14, 64)  # Weights for first hidden layer (14 input features, 64 neurons)\n",
        "b1 = np.random.rand(1, 64)   # Bias for first hidden layer (64 neurons)\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Forward Propagation for the first hidden layer\n",
        "Z1 = np.dot(X, W1) + b1  # Linear transformation\n",
        "A1 = np.maximum(0, Z1)   # ReLU activation\n",
        "\n",
        "# Assuming we have a loss gradient with respect to A1\n",
        "dA1 = np.random.rand(100, 64)  # Gradient of loss with respect to A1\n",
        "\n",
        "# Backward Propagation for the first hidden layer\n",
        "dZ1 = dA1 * (Z1 > 0)  # Derivative of ReLU\n",
        "dW1 = np.dot(X.T, dZ1)  # Gradient of loss with respect to W1\n",
        "db1 = np.sum(dZ1, axis=0, keepdims=True)  # Gradient of loss with respect to b1\n",
        "\n",
        "# Update weights and biases\n",
        "W1 -= learning_rate * dW1\n",
        "b1 -= learning_rate * db1\n",
        "\n",
        "print(\"Updated Weights:\", W1)\n",
        "print(\"Updated Biases:\", b1)"
      ],
      "metadata": {
        "id": "sueN-aTsB0S-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Forward Propagation:\n",
        "        The input X is multiplied by the weight matrix W and added to the bias b to get Z1.\n",
        "        The ReLU activation function then applies A1 = max(0, Z1).\n",
        "\n",
        "    Backward Propagation:\n",
        "        We compute the gradient of the loss with respect to A1 which is then used to calculate gradients for Z1.\n",
        "        These gradients are used to update the weights W1 and biases b1 using gradient descent.\n",
        "\n",
        "This approach provides a clear view of how the data propagates through the network and how the weights and biases are adjusted during training. This can be directly related to your dataset and network configuration."
      ],
      "metadata": {
        "id": "0PlHxiPGFjro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the backpropagation step, it appears that the updated weights have undergone significant changes, reflecting the adjustments made to minimize the loss during training. These changes are a positive sign that the model is learning from the data and refining its predictions. The weights have likely been updated to better capture the relationships within the dataset, which should enhance the model's performance.\n",
        "\n",
        "Monitoring the loss and validation accuracy will provide a clearer picture of how well the model is performing following these updates. If the loss is decreasing steadily, it indicates that the model is making progress towards convergence."
      ],
      "metadata": {
        "id": "yZ5b9qHHFXB-"
      }
    }
  ]
}